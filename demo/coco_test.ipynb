{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing detectron2 mask r-cnn with COCO \n",
    "\n",
    "import detectron2 \n",
    "\n",
    "#Setup logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "#Some common libraries \n",
    "import numpy as np \n",
    "import os,json,cv2,random \n",
    "\n",
    "\n",
    "#Detectron2 utilities \n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg \n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(r\"/Users/HeleneSemb/Documents/Master/Kode /images/input.png\")\n",
    "cv2.imshow(\"image\",im)\n",
    "cv2.waitKey(0)\n",
    "  \n",
    "# closing all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 10:17:43 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f10217.pkl: 178MB [00:15, 11.7MB/s]                              \n",
      "/Users/HeleneSemb/opt/miniconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg() \n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 #treshold for this model \n",
    "\n",
    "cfg.MODEL.DEVICE='cpu'\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 10:22:21.216 python[38994:1430258] Warning: Window move completed without beginning\n"
     ]
    }
   ],
   "source": [
    "v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "cv2.imshow(\"imageout\", out.get_image()[:,:,::-1])\n",
    "cv2.waitKey(0)\n",
    "  \n",
    "# closing all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset: Balloons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode \n",
    "\n",
    "def get_balloon_dicts(img_dir): \n",
    "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
    "    with open(json_file) as f: \n",
    "        imgs_anns = json.load(f)\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "\n",
    "        filename = os.path.join(img_dir, v[\"filename\"])\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx \n",
    "        record[\"height\"] = height \n",
    "        record[\"width\"] = width \n",
    "\n",
    "        annos = v[\"regions\"]\n",
    "        objs = []\n",
    "\n",
    "        for _, anno in annos.items():\n",
    "            assert not anno[\"region_attributes\"]\n",
    "            anno = anno[\"shape_attributes\"]\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px,py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS, \n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        \n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record) \n",
    "    return dataset_dicts\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(r\"/Users/HeleneSemb/Documents/Master/Kode/balloon/\" + d))\n",
    "    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
    "\n",
    "balloon_metadata = MetadataCatalog.get(\"ballon_train\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = get_balloon_dicts(r\"/Users/HeleneSemb/Documents/Master/Kode /balloon/train\")\n",
    "for d in random.sample(dataset_dicts, 1): \n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:,:,::-1], metadata = balloon_metadata, scale =0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imshow(\"imageout\", out.get_image()[:,:,::-1])\n",
    "    cv2.waitKey(0)\n",
    "    # closing all open windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 11:44:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/23 11:44:21 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 61 images left.\n",
      "\u001b[32m[01/23 11:44:21 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  balloon   | 255          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/23 11:44:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/23 11:44:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/23 11:44:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/23 11:44:21 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/23 11:44:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.17 MiB\n",
      "\u001b[32m[01/23 11:44:22 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 11:44:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HeleneSemb/opt/miniconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 11:51:06 d2.utils.events]: \u001b[0m eta: 1:31:32  iter: 19  total_loss: 2.096  loss_cls: 0.7468  loss_box_reg: 0.5747  loss_mask: 0.684  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.006547  time: 19.4967  data_time: 0.6553  lr: 1.6068e-05  \n",
      "\u001b[32m[01/23 11:57:25 d2.utils.events]: \u001b[0m eta: 1:26:46  iter: 39  total_loss: 1.949  loss_cls: 0.6027  loss_box_reg: 0.7474  loss_mask: 0.5953  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.004719  time: 19.1845  data_time: 0.0072  lr: 3.2718e-05  \n",
      "\u001b[32m[01/23 12:04:44 d2.utils.events]: \u001b[0m eta: 1:20:15  iter: 59  total_loss: 1.785  loss_cls: 0.4711  loss_box_reg: 0.7579  loss_mask: 0.4797  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.004164  time: 20.1472  data_time: 0.0077  lr: 4.9367e-05  \n",
      "\u001b[32m[01/23 12:11:22 d2.utils.events]: \u001b[0m eta: 1:13:18  iter: 79  total_loss: 1.322  loss_cls: 0.3402  loss_box_reg: 0.6669  loss_mask: 0.3171  loss_rpn_cls: 0.006203  loss_rpn_loc: 0.002194  time: 20.0796  data_time: 0.0076  lr: 6.6017e-05  \n",
      "\u001b[32m[01/23 12:18:31 d2.utils.events]: \u001b[0m eta: 1:06:39  iter: 99  total_loss: 1.148  loss_cls: 0.2751  loss_box_reg: 0.5383  loss_mask: 0.2381  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.003463  time: 20.3549  data_time: 0.0108  lr: 8.2668e-05  \n",
      "\u001b[32m[01/23 12:25:04 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 119  total_loss: 1.24  loss_cls: 0.2506  loss_box_reg: 0.7051  loss_mask: 0.2238  loss_rpn_cls: 0.02308  loss_rpn_loc: 0.005234  time: 20.2321  data_time: 0.0077  lr: 9.9318e-05  \n",
      "\u001b[32m[01/23 12:31:32 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 139  total_loss: 0.8674  loss_cls: 0.181  loss_box_reg: 0.5098  loss_mask: 0.1601  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.004154  time: 20.1113  data_time: 0.0102  lr: 0.00011597  \n",
      "\u001b[32m[01/23 12:36:28 d2.utils.events]: \u001b[0m eta: 0:42:06  iter: 159  total_loss: 0.9808  loss_cls: 0.1569  loss_box_reg: 0.6996  loss_mask: 0.1469  loss_rpn_cls: 0.005185  loss_rpn_loc: 0.003915  time: 19.4377  data_time: 0.0045  lr: 0.00013262  \n",
      "\u001b[32m[01/23 12:40:45 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 179  total_loss: 0.6525  loss_cls: 0.09287  loss_box_reg: 0.4388  loss_mask: 0.09382  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.003284  time: 18.6974  data_time: 0.0033  lr: 0.00014927  \n",
      "\u001b[32m[01/23 12:45:28 d2.utils.events]: \u001b[0m eta: 0:27:39  iter: 199  total_loss: 0.5469  loss_cls: 0.08732  loss_box_reg: 0.3357  loss_mask: 0.09446  loss_rpn_cls: 0.01548  loss_rpn_loc: 0.004516  time: 18.2402  data_time: 0.0036  lr: 0.00016592  \n",
      "\u001b[32m[01/23 12:49:56 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 219  total_loss: 0.3421  loss_cls: 0.07948  loss_box_reg: 0.2017  loss_mask: 0.07832  loss_rpn_cls: 0.004227  loss_rpn_loc: 0.006972  time: 17.7947  data_time: 0.0035  lr: 0.00018257  \n",
      "\u001b[32m[01/23 12:54:21 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 239  total_loss: 0.3599  loss_cls: 0.05522  loss_box_reg: 0.1991  loss_mask: 0.07156  loss_rpn_cls: 0.007528  loss_rpn_loc: 0.003825  time: 17.4103  data_time: 0.0021  lr: 0.00019922  \n",
      "\u001b[32m[01/23 12:58:54 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 259  total_loss: 0.3341  loss_cls: 0.05369  loss_box_reg: 0.2144  loss_mask: 0.07573  loss_rpn_cls: 0.003062  loss_rpn_loc: 0.003713  time: 17.1186  data_time: 0.0032  lr: 0.00021587  \n",
      "\u001b[32m[01/23 13:03:06 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 279  total_loss: 0.3071  loss_cls: 0.06158  loss_box_reg: 0.178  loss_mask: 0.06479  loss_rpn_cls: 0.002746  loss_rpn_loc: 0.003695  time: 16.7940  data_time: 0.0021  lr: 0.00023252  \n",
      "\u001b[32m[01/23 13:08:09 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.2707  loss_cls: 0.0561  loss_box_reg: 0.1489  loss_mask: 0.05566  loss_rpn_cls: 0.00793  loss_rpn_loc: 0.002506  time: 16.6722  data_time: 0.0058  lr: 0.00024917  \n",
      "\u001b[32m[01/23 13:08:09 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 1:22:48 (16.6722 s / it)\n",
      "\u001b[32m[01/23 13:08:09 d2.engine.hooks]: \u001b[0mTotal training time: 1:22:53 (0:00:05 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg() \n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"balloon_train\")\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.DATALOADER.NUM_WORKERS = 2 \n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1 \n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 300 \n",
    "cfg.SOLVER.STEPS = [] \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 43302), started 0:05:08 ago. (Use '!kill 43302' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f4f6f46ad420b542\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f4f6f46ad420b542\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:31:51 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /Users/HeleneSemb/Documents/Master/Kode/output/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(r\"/Users/HeleneSemb/Documents/Master/Kode/output\", \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode \n",
    "dataset_dicts = get_balloon_dicts(r\"/Users/HeleneSemb/Documents/Master/Kode/balloon/val\")\n",
    "for d in random.sample(dataset_dicts, 1): \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                    metadata = balloon_metadata,\n",
    "                    scale = 0.5,\n",
    "                    instance_mode = ColorMode.IMAGE_BW)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(\"image\",out.get_image()[:,:,::-1])\n",
    "    cv2.waitKey(0)\n",
    "    # closing all open windows\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:42:37 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'balloon_val' to COCO format ...\n",
      "\u001b[32m[01/23 14:42:37 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'balloon_val' to COCO format ...)\n",
      "\u001b[32m[01/23 14:42:38 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[01/23 14:42:39 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 13, #annotations: 50\n",
      "\u001b[32m[01/23 14:42:39 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/Users/HeleneSemb/Documents/Master/Kode/output/balloon_val_coco_format.json' ...\n",
      "\u001b[32m[01/23 14:42:39 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  balloon   | 50           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/23 14:42:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/23 14:42:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/23 14:42:39 d2.data.common]: \u001b[0mSerializing 13 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/23 14:42:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[32m[01/23 14:42:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 13 batches\n",
      "\u001b[32m[01/23 14:43:02 d2.evaluation.evaluator]: \u001b[0mInference done 1/13. Dataloading: 10.0071 s/iter. Inference: 12.5689 s/iter. Eval: 0.0295 s/iter. Total: 22.6694 s/iter. ETA=0:04:32\n",
      "\u001b[32m[01/23 14:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 2/13. Dataloading: 5.0063 s/iter. Inference: 10.5206 s/iter. Eval: 0.0661 s/iter. Total: 15.6342 s/iter. ETA=0:02:51\n",
      "\u001b[32m[01/23 14:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 3/13. Dataloading: 3.3384 s/iter. Inference: 10.2346 s/iter. Eval: 0.0932 s/iter. Total: 13.6942 s/iter. ETA=0:02:16\n",
      "\u001b[32m[01/23 14:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 4/13. Dataloading: 2.5053 s/iter. Inference: 10.2114 s/iter. Eval: 0.1114 s/iter. Total: 12.8521 s/iter. ETA=0:01:55\n",
      "\u001b[32m[01/23 14:43:40 d2.evaluation.evaluator]: \u001b[0mInference done 5/13. Dataloading: 2.0054 s/iter. Inference: 9.8774 s/iter. Eval: 0.1205 s/iter. Total: 12.0248 s/iter. ETA=0:01:36\n",
      "\u001b[32m[01/23 14:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 6/13. Dataloading: 0.0000 s/iter. Inference: 9.6196 s/iter. Eval: 0.0259 s/iter. Total: 9.6456 s/iter. ETA=0:01:07\n",
      "\u001b[32m[01/23 14:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 7/13. Dataloading: 0.0034 s/iter. Inference: 11.9080 s/iter. Eval: 0.0146 s/iter. Total: 11.9323 s/iter. ETA=0:01:11\n",
      "\u001b[32m[01/23 14:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 8/13. Dataloading: 0.0044 s/iter. Inference: 10.6337 s/iter. Eval: 0.0108 s/iter. Total: 10.6572 s/iter. ETA=0:00:53\n",
      "\u001b[32m[01/23 14:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 9/13. Dataloading: 0.0038 s/iter. Inference: 9.6714 s/iter. Eval: 0.0088 s/iter. Total: 9.6905 s/iter. ETA=0:00:38\n",
      "\u001b[32m[01/23 14:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 10/13. Dataloading: 0.0033 s/iter. Inference: 9.5035 s/iter. Eval: 0.0100 s/iter. Total: 9.5225 s/iter. ETA=0:00:28\n",
      "\u001b[32m[01/23 14:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/13. Dataloading: 0.0029 s/iter. Inference: 9.4037 s/iter. Eval: 0.0089 s/iter. Total: 9.4205 s/iter. ETA=0:00:18\n",
      "\u001b[32m[01/23 14:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 12/13. Dataloading: 0.0031 s/iter. Inference: 9.3182 s/iter. Eval: 0.0088 s/iter. Total: 9.3362 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/23 14:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 13/13. Dataloading: 0.0029 s/iter. Inference: 9.1523 s/iter. Eval: 0.0090 s/iter. Total: 9.1698 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:15.288208 (9.411026 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:13 (9.152286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /Users/HeleneSemb/Documents/Master/Kode/output/coco_instances_results.json\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.873\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.854\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.830\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 67.811 | 87.266 | 85.395 | 0.000 | 55.493 | 80.023 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.853\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.853\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.946\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.796\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.796\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.960\n",
      "\u001b[32m[01/23 14:44:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 78.122 | 85.342 | 85.342 | 0.000 | 59.143 | 94.641 |\n",
      "OrderedDict([('bbox', {'AP': 67.81050361937353, 'AP50': 87.26555582387508, 'AP75': 85.39477091929767, 'APs': 0.0, 'APm': 55.492599712459935, 'APl': 80.02270941379854}), ('segm', {'AP': 78.12158969664499, 'AP50': 85.3417384421369, 'AP75': 85.3417384421369, 'APs': 0.0, 'APm': 59.14256971915679, 'APl': 94.64075175990506})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset \n",
    "from detectron2.data import build_detection_test_loader \n",
    "evaluator = COCOEvaluator(\"balloon_val\", output_dir = \"/Users/HeleneSemb/Documents/Master/Kode/output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cffc46db8279bf945e3b0aed049738acb42224b6bc56a9c400cd463b367b51fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
