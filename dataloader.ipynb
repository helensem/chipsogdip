{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HeleneSemb/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## imports \n",
    "\n",
    "# For testing detectron2 mask r-cnn with COCO \n",
    "\n",
    "import detectron2 \n",
    "\n",
    "#Setup logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "#Some common libraries \n",
    "import numpy as np \n",
    "import os,json,cv2,random \n",
    "\n",
    "\n",
    "#Detectron2 utilities \n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg \n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/27 11:30:20 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /Volumes/helensem/Master/output/run1/resnet50/model_final.pth ...\n",
      "\u001b[32m[02/27 11:30:20 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /Volumes/helensem/Master/output/run1/resnet50/model_final.pth ...\n",
      "/Volumes/helensem/Master/data/train/000004\n",
      "/Volumes/helensem/Master/data/train/000004/1.png\n",
      "/Volumes/helensem/Master/data/train/000004/masks/grov_merking_0.png\n",
      "/Volumes/helensem/Master/data/train/000006\n",
      "/Volumes/helensem/Master/data/train/000006/1.png\n",
      "/Volumes/helensem/Master/data/train/000006/masks/grov_merking_0.png\n",
      "/Volumes/helensem/Master/data/train/000001\n",
      "/Volumes/helensem/Master/data/train/000001/1.png\n",
      "/Volumes/helensem/Master/data/train/000001/masks/grov_merking_0.png\n",
      "/Volumes/helensem/Master/data/train/000001/masks/grov_merking_2.png\n",
      "/Volumes/helensem/Master/data/train/000001/masks/grov_merking_1.png\n",
      "/Volumes/helensem/Master/data/train/000001/masks/grov_merking_3.png\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(r\"/Users/HeleneSemb/Documents/chipsogdip/kode\")\n",
    "from kode.training import *\n",
    "from kode.dataset import * \n",
    "from detectron2.structures import BoxMode \n",
    "from detectron2.utils.visualizer import ColorMode \n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "#for d in [\"train\", \"val\"]:\n",
    " #   DatasetCatalog.register(\"damage_\" + d, lambda d=d: load_damage_dicts(r\"/Volumes/helensem/Master/Labeled_pictures\", d))\n",
    "  #  MetadataCatalog.get(\"damage_\" + d).set(thing_classes=[\"damage\"])\n",
    "\n",
    "cfg = get_cfg() \n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"damage_train\")\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.DATALOADER.NUM_WORKERS = 2 \n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1 \n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 300 \n",
    "cfg.SOLVER.STEPS = [] \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n",
    "\n",
    "cfg.OUTPUT_DIR = \"/Volumes/helensem/Master/output/run1/resnet50\"\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "\n",
    "predictor = DefaultPredictor(cfg) \n",
    "damage_metadata = MetadataCatalog.get(\"damage_train\")\n",
    "\n",
    "dataset_dicts = load_damage_dicts(r\"/Volumes/helensem/Master/data\", \"train\") #our testing folder\n",
    "for d in random.sample(dataset_dicts, 1): \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                    metadata = damage_metadata,\n",
    "                    scale = 0.5,\n",
    "                    instance_mode = ColorMode.IMAGE)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite(r\"/Users/HeleneSemb/Documents/images/img.jpg\", out.get_image()[:,:,::-1]) #* Save images \n",
    "    cv2.imshow(\"image\",out.get_image()[:,:,::-1])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpeg\n",
      "/Volumes/helensem/Master/output/run1/resnet101/images/0.jpeg\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "  \n",
    "# importing shutil module \n",
    "import shutil \n",
    "  \n",
    "# path \n",
    "path = r\"/Volumes/helensem/Master/Labeled_pictures/val/0/0.jpeg\"\n",
    "\n",
    "\n",
    "dest = r\"/Volumes/helensem/Master/output/run1/resnet101/images\"\n",
    "\n",
    "\n",
    "#source = os.path.join(path, image)\n",
    "#print(source)\n",
    "image_id = next(os.walk((os.path.dirname(path))))[2][0]\n",
    "print(image_id)\n",
    "full_output = os.path.join(dest, image_id)\n",
    "#full_output = output + \".jpg\"\n",
    "print(full_output)\n",
    "\n",
    "\n",
    "#     \n",
    "#     destination = os.path.join(dest, image)\n",
    "#     if image.endswith(\".jpg\"):\n",
    "#         shutil.move(source,destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "array = np.zeros((1,2,3))\n",
    "array = array.T \n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HeleneSemb/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks\n",
      "\u001b[32m[02/28 11:40:48 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /Volumes/helensem/Master/output/run1/resnet101/model_final.pth ...\n",
      "\u001b[32m[02/28 11:40:48 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /Volumes/helensem/Master/output/run1/resnet101/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HeleneSemb/opt/miniconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_6.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_7.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_4.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_2.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_1.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_9.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_8.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_5.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_10.png\n",
      "/Volumes/helensem/Master/Labeled_pictures/val/0/masks/grov_merking_3.png\n",
      "img:  (512, 512, 3)\n",
      "mask:  (512, 512, 10)\n",
      "pred:  (512, 512, 54)\n",
      "(512, 512, 1)\n",
      "(512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(r\"/Users/HeleneSemb/Documents/chipsogdip/kode\")\n",
    "from kode.training import *\n",
    "from kode.dataset import * \n",
    "import cv2 \n",
    "from kode.eval import combine_masks_to_one\n",
    "\n",
    "path = r\"/Volumes/helensem/Master/Labeled_pictures/val/0/0.jpeg\"\n",
    "mask_path = os.path.dirname(path)\n",
    "mask_path = os.path.join(mask_path, \"masks\")\n",
    "print(mask_path)\n",
    "image = cv2.imread(path)\n",
    "cfg = config()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"/Volumes/helensem/Master/output/run1/resnet101\", \"model_final.pth\")\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "output = predictor(image)\n",
    "\n",
    "\n",
    "mask_gt = load_mask(mask_path)\n",
    "predicted_masks = output['instances'].to(\"cpu\").pred_masks.numpy()\n",
    "predicted_masks = predicted_masks.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"img: \", image.shape)\n",
    "print(\"mask: \", mask_gt.shape)\n",
    "print(\"pred: \", predicted_masks.shape)\n",
    "\n",
    "mask_gt = combine_masks_to_one(mask_gt)\n",
    "mask_pred = combine_masks_to_one(predicted_masks)\n",
    "\n",
    "print(mask_gt.shape)\n",
    "print(mask_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode \n",
    "\n",
    "\n",
    "def find_contours(sub_mask):\n",
    "    assert sub_mask is not None, \"file could not be read, check with os.path.exists()\"\n",
    "    imgray = cv2.cvtColor(sub_mask, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours[0]\n",
    "\n",
    "\n",
    "def create_image_annotation(file_name, width, height, image_id):\n",
    "    return {\n",
    "        \"id\": image_id,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"file_name\": file_name,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_annotation_format(contour):\n",
    "    return {\n",
    "        \"iscrowd\": 0,\n",
    "        \"segmentation\": [contour.flatten().tolist()],\n",
    "        \"bbox\": cv2.boundingRect(contour),\n",
    "        \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "        \"category_id\": 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "\n",
    "def load_damage_dicts(dataset_dir, subset): \n",
    "    dataset_dicts = []\n",
    "\n",
    "    assert subset in [\"train\", \"val\"]\n",
    "    dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    image_ids = next(os.walk(dataset_dir))[1]\n",
    "    for image_id in image_ids:\n",
    "\n",
    "        image_dir = os.path.join(dataset_dir, image_id)\n",
    "        (_, _, file_names) = next(os.walk(image_dir))\n",
    "        file_name = file_names[0]\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "        height, width = cv2.imread(image_path).shape[:2]\n",
    "        record = create_image_annotation(image_path, width, height, image_id)\n",
    "\n",
    "        mask_dir = os.path.join(image_dir, 'masks')\n",
    "        objs = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith('.png') and ('corrosion' or 'grov_merking' in f):\n",
    "                mask_path = os.path.join(mask_dir, f)\n",
    "                mask = cv2.imread(mask_path)\n",
    "                contour = find_contours(mask)\n",
    "                obj = create_annotation_format(contour)\n",
    "                objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"damage_\" + d, lambda d=d: load_damage_dicts(r\"/Users/HeleneSemb/Documents/Master/chipsogdip\", \"train\"))\n",
    "    MetadataCatalog.get(\"damage_\" + d).set(thing_classes=[\"damage\"])\n",
    "\n",
    "balloon_metadata = MetadataCatalog.get(\"damage_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = load_damage_dicts(r\"/Users/HeleneSemb/Documents/Master/chipsogdip\", \"train\")\n",
    "for d in random.sample(dataset_dicts, 1): \n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:,:,::-1], metadata = balloon_metadata, scale =0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imshow(\"imageout\", out.get_image()[:,:,::-1])\n",
    "    cv2.waitKey(0)\n",
    "    # closing all open windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 6407), started 0:14:21 ago. (Use '!kill 6407' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db9d39713b1c8376\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db9d39713b1c8376\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /Volumes/helensem/Master/output/run1/resnet50\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cffc46db8279bf945e3b0aed049738acb42224b6bc56a9c400cd463b367b51fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
